#!/usr/bin/env python
#
# Utilities for running parameter sweeps on slurm

import argparse
import datetime
import errno
import getpass
import hashlib
import json
import os
import sys

from subprocess import check_output
from itertools import product

job_name_suffix = ''


def product_dict(**kwargs):
    keys = kwargs.keys()
    vals = kwargs.values()
    for instance in product(*vals):
        yield dict(zip(keys, instance))


def generate_job(jid, params, job_str, env, sbatch_args, job_dir, logs_dir):
    jname = 'job_{}_{}'.format(str(jid).zfill(3), job_name_suffix)
    fname = os.path.join(job_dir, jname)
    with open(fname, 'w') as f:
        f.write('#!/bin/bash\n\n')
        f.write('#SBATCH -e {}/{}.err\n'.format(logs_dir, jname))
        f.write('#SBATCH -o {}/{}.out\n'.format(logs_dir, jname))
        f.write('#SBATCH -J {}\n'.format(jname))
        f.write('#SBATCH -N {}\n'.format(params['nodes']))
        for k, v in sbatch_args.items():
            f.write('#SBATCH --{} {}\n'.format(k, v))
        f.write('')
        for k, v in env.items():
            v_eval = check_output('echo "' + v + '"', shell=True)
            f.write('export {}={}'.format(k, v_eval))
        for k, v in params.items():
            f.write('export {}={}\n'.format(k, v))
        f.write('\n{}\n'.format(job_str))
    os.chmod(fname, 0755)


def info(msg):
    print('[slurmp]: ' + msg)


def generate(c, job_file, job_dir, logs_dir):
    all_job_parameters = {}

    # check required items
    if not c.get('params', None):
        info("Expecting 'params' element in configuration.")
    if not c['params'].get('nodes', None):
        info("Expecting 'params.nodes' element in configuration.")

    # check types
    for k, v in c['params'].items():
        if type(v) is not list:
            info("Expecting only lists (arrays) in 'params' dictionary.")
    for k, v in c.get('env', {}).items():
        if type(v) is not str:
            info("Expecting only strings as values in 'env' dictionary.")
    for k, v in c.get('sbatch_args', {}).items():
        if type(v) is not str:
            info("Expecting only strings as values of 'sbatch_args' dict.")

    with open(job_file, 'r') as f:
        job_str = f.read()

    jid = 1
    for p in list(product_dict(**c['params'])):
        generate_job(jid, p, job_str, c['env'],
                     c['sbatch_args'], job_dir, logs_dir)
        all_job_parameters.update({'job_{}_{}'.format(ts, jid): p})
        jid += 1

    all_jobs_file = os.path.join(os.path.dirname(job_file), 'all_jobs_params')
    with open(all_jobs_file, 'wb') as f:
        f.write(json.dumps(all_job_parameters, sort_keys=True, indent=4))


def job_files(job_dir):
    jobfs = []
    for f in os.listdir(job_dir):
        if not os.path.isfile(os.path.join(job_dir, f)):
            continue
        jobfs.append(f)
    return jobfs


def run(job_dir, sequential):
    jfiles = job_files(job_dir)
    sbatch_flags = ''
    for f in jfiles:
        cmd = 'sbatch {} {}'.format(sbatch_flags, os.path.join(job_dir, f))
        check_output(cmd, shell=True)
        if sequential:
            sbatch_flags = '--dependency afterany:{}'.format(f)
    info('Submitted jobs successfully!')


def wait(job_dir, sleep_length=120):
    jobs_all = set(job_files(job_dir))
    jobs_done = set()

    cmd = 'squeue --user {u} --name {j} --noheader | wc -l'

    u = getpass.getuser()

    info('Waiting for jobs to finish.')

    while jobs_done != jobs_all:

        jobs_remaining = jobs_all - jobs_done

        info('{} jobs remain in the queue'.format(len(jobs_remaining)))

        time.sleep(float(sleep_length))

        for j in jobs_remaining:
            if int(check_output(cmd.format(u=u, j=j), shell=True)) == 0:
                info("Job {} finished.".format(j))
                jobs_done.add(j)

    info('All jobs finished.')


def mkdir_p(path):
    try:
        os.makedirs(path)
    except OSError as exc:  # Python >2.5
        if exc.errno == errno.EEXIST and os.path.isdir(path):
            pass
        else:
            raise


if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    cmd_choice = ['run', 'generate']

    parser.add_argument(
        'command',
        help="Command to execute ('{}')".format("', '".join(cmd_choice)))

    parser.add_argument(
        '--config',
        help='Path to parameter sweep configuration file.',
        default='./slurm/sweep.py',
        required=False
    )
    parser.add_argument(
        '--job-file',
        help='Job to be used in the generation of the sweep.',
        default="./slurm/job.sh",
        required=False
    )
    parser.add_argument(
        '--sleep-length',
        help='Number of seconds to sleep between checks of SLURM job state.',
        default='30',
        required=False
    )
    parser.add_argument(
        '--job-dir',
        help='Folder where job files are to be written.',
        default="./slurm/jobs",
        required=False
    )
    parser.add_argument(
        '--logs-dir',
        help='Folder where job logs are to be written.',
        default="./slurm/logs",
        required=False
    )
    parser.add_argument(
        '--sequential',
        help='Run jobs sequentially.',
        required=False,
        action='store_true'
    )
    parser.add_argument(
        '--no-wait',
        required=False,
        help='Do not wait for jobs and return after they have been submitted.',
        action='store_true'
    )

    args = vars(parser.parse_args())
    slurmpcmd = args['command']

    if args['no_wait'] and slurmpcmd != 'run':
        print("The --no-wait flag works with the 'run' command.")
        sys.exit(1)
    if args['sequential'] and slurmpcmd != 'run':
        print("The --sequential flag works with the 'run' command.")
        sys.exit(1)

    job_name_suffix = hashlib.sha256(
        os.path.join(os.getcwd(), args['job_dir'])).hexdigest()[:3]

    mkdir_p(args['job_dir'])

    if slurmpcmd == 'generate':
        if not os.path.isfile(args['job_file']):
            print('ERROR: {} does not exist'.format(args['job_file']))
            sys.exit(1)
        if not os.path.isfile(args['config']):
            print('ERROR: {} does not exist'.format(args['config']))
            sys.exit(1)

        with open(args['config'], 'r') as f:
            c = eval(f.read())

        generate(c, args['job_file'], args['job_dir'], args['logs_dir'])

        sys.exit(0)

    if slurmpcmd == 'run':
        if not os.path.isdir(args['job_dir']):
            print('ERROR: {} does not exist'.format(args['config']))
            sys.exit(1)
        if len(job_files(args['job_dir'])) == 0:
            print('ERROR: {} is empty'.format(args['job_dir']))
            sys.exit(1)

        run(args['job_dir'], sequential['sequential'])

        if args['no_wait']:
            sys.exit(0)

        wait(args['job_dir'], args['sleep_length'])
